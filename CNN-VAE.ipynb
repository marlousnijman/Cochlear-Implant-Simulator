{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /home/s4551400b/anaconda3/lib/python3.7/site-packages (0.23.1)\n",
      "Requirement already satisfied: librosa in /home/s4551400b/anaconda3/lib/python3.7/site-packages (0.6.3)\n",
      "Requirement already satisfied: numba>=0.38.0 in /home/s4551400b/anaconda3/lib/python3.7/site-packages (from librosa) (0.43.1)\n",
      "Requirement already satisfied: joblib>=0.12 in /home/s4551400b/anaconda3/lib/python3.7/site-packages (from librosa) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/s4551400b/anaconda3/lib/python3.7/site-packages (from librosa) (0.20.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/s4551400b/anaconda3/lib/python3.7/site-packages (from librosa) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /home/s4551400b/anaconda3/lib/python3.7/site-packages (from librosa) (1.16.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/s4551400b/anaconda3/lib/python3.7/site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: six>=1.3 in /home/s4551400b/anaconda3/lib/python3.7/site-packages (from librosa) (1.12.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /home/s4551400b/anaconda3/lib/python3.7/site-packages (from librosa) (2.1.7)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /home/s4551400b/anaconda3/lib/python3.7/site-packages (from librosa) (0.2.1)\n",
      "Requirement already satisfied: llvmlite>=0.28.0dev0 in /home/s4551400b/anaconda3/lib/python3.7/site-packages (from numba>=0.38.0->librosa) (0.28.0)\n",
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/s4551400b/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit=9.0\n",
      "    - pytorch\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.3.9           |           py37_0         155 KB\n",
      "    torchvision-0.3.0          | py37_cu9.0.176_1         3.7 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.8 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  torchvision        pytorch/noarch::torchvision-0.2.2-py_3 --> pytorch/linux-64::torchvision-0.3.0-py37_cu9.0.176_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                       conda-forge --> pkgs/main\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "torchvision-0.3.0    | 3.7 MB    | ##################################### | 100% \n",
      "certifi-2019.3.9     | 155 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/s4551400b/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.6.14               |           py37_0         2.1 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.1 MB\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  conda                                         conda-forge --> pkgs/main\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "conda-4.6.14         | 2.1 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/s4551400b/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - ffmpeg\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.3.9           |           py37_0         149 KB  conda-forge\n",
      "    conda-4.6.14               |           py37_0         2.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.2 MB\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                         pkgs/main --> conda-forge\n",
      "  conda                                           pkgs/main --> conda-forge\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2019.3.9     | 149 KB    | ##################################### | 100% \n",
      "conda-4.6.14         | 2.1 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub\n",
    "!pip install librosa\n",
    "!conda install pytorch torchvision cudatoolkit=9.0 -c pytorch --yes \n",
    "!conda install torchvision --yes\n",
    "!conda install -c conda-forge ffmpeg --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import All Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compute_frequency_ranges as freqs\n",
    "import cochlear_implant_simulator as sim\n",
    "import spectrogram as spec\n",
    "import helper_functions as func\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File/Directory Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Original Data\n",
    "  # Training\n",
    "training_noisy_dir = \"noisy_trainset_28spk_wav\"\n",
    "training_clean_dir = \"clean_trainset_28spk_wav\"    \n",
    "  # Testing\n",
    "testing_noisy_dir = \"noisy_testset_wav\"\n",
    "testing_clean_dir = \"clean_testset_wav\"\n",
    "\n",
    "### Resampled Data\n",
    "  # Training\n",
    "training_noisy_dir_resampled = training_noisy_dir + \"_resampled\"\n",
    "training_clean_dir_resampled = training_clean_dir + \"_resampled\"\n",
    " # Testing     \n",
    "testing_noisy_dir_resampled = testing_noisy_dir + \"_resampled\"\n",
    "testing_clean_dir_resampled = testing_clean_dir + \"_resampled\"\n",
    "    \n",
    "### Chunk Data\n",
    "  # Training\n",
    "training_noisy_dir_chunks = training_noisy_dir + \"_chunks\"\n",
    "training_clean_dir_chunks = training_clean_dir + \"_chunks\"\n",
    "  # Training\n",
    "testing_noisy_dir_chunks = testing_noisy_dir + \"_chunks\"\n",
    "testing_clean_dir_chunks = testing_clean_dir + \"_chunks\"\n",
    "    \n",
    "### Trained Model\n",
    "trainedVAE = \"trainedVAE.pth\"\n",
    "    \n",
    "### Testing Results\n",
    "testing_results_dir = \"testset_results_wav\"\n",
    "    \n",
    "### Simulated Data\n",
    "    # Original \n",
    "testing_noisy_dir_simulated = testing_noisy_dir + \"_simulated\"\n",
    "    # Processed\n",
    "testing_results_dir_simulated = testing_results_dir + \"_simulated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample\n",
    "\n",
    "Resamples the sound fragments from 48000Hz down to 16000Hz, while maintaining the same lenght of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rate = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.resample(training_noisy_dir, training_noisy_dir_resampled, new_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.resample(training_clean_dir, training_clean_dir_resampled, new_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.resample(testing_noisy_dir, testing_noisy_dir_resampled, new_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.resample(testing_clean_dir, testing_clean_dir_resampled, new_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide Data Into Chunks \n",
    "\n",
    "The sound fragments are divided into chunks of equal size (chunk_lenght_ms), resulting in an array of size data_len."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_length_ms = 250\n",
    "data_len = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.create_chunks(training_noisy_dir_resampled, training_noisy_dir_chunks, chunk_length_ms)\n",
    "func.create_chunks(training_clean_dir_resampled, training_clean_dir_chunks, chunk_length_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.create_chunks(testing_noisy_dir_resampled, testing_noisy_dir_chunks, chunk_length_ms)\n",
    "func.create_chunks(testing_clean_dir_resampled, testing_clean_dir_chunks, chunk_length_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Load in both the training and testing data. The noisy and clean samples are zipped to form tuples. These tuples will be used as input to the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_noisy_data = func.load_data(training_noisy_dir_chunks, data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_clean_data = func.load_data(training_clean_dir_chunks, data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = list(zip(training_noisy_data, training_clean_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_noisy_data = func.load_data(testing_noisy_dir_chunks, data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_clean_data = func.load_data(testing_clean_dir_chunks, data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = list(zip(testing_noisy_data, testing_clean_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Nework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle_neck = 2000\n",
    "train_batch_size = 1024\n",
    "test_batch_size = 1024\n",
    "h_layer = 512 * 2 * 3\n",
    "im_size = 112 * 256\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_training_data = len(training_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([140925, 2, 4000])\n"
     ]
    }
   ],
   "source": [
    "train_tensor = torch.tensor(training_data, dtype = torch.float32)\n",
    "print(train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.95 * len_training_data)\n",
    "val_size = len_training_data - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(train_tensor[0:len_training_data], (train_size, val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=train_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Testing Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8689, 2, 4000])\n"
     ]
    }
   ],
   "source": [
    "test_tensor = torch.tensor(testing_data, dtype = torch.float32)\n",
    "print(test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_tensor, batch_size = test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, bottle_neck = bottle_neck, h_layer = h_layer):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(5,5), stride=1)\n",
    "        nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(5,5), stride=1)\n",
    "        nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(4,4), stride=1)\n",
    "        nn.init.xavier_uniform_(self.conv3.weight)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)        \n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=(4,4), stride=1)\n",
    "        nn.init.xavier_uniform_(self.conv4.weight)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)        \n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=(1,4), stride=1)\n",
    "        nn.init.xavier_uniform_(self.conv5.weight)\n",
    "        self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)        \n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size=(1,3), stride=1)\n",
    "        nn.init.xavier_uniform_(self.conv6.weight)\n",
    "        \n",
    "        # Reparameterize\n",
    "        self.f11 = nn.Linear(h_layer, bottle_neck)\n",
    "        self.f12 = nn.Linear(h_layer, bottle_neck)\n",
    "        self.f2 = nn.Linear(bottle_neck, h_layer)\n",
    "        \n",
    "        #  Decoder\n",
    "        self.deconv6 = nn.ConvTranspose2d(512, 256, kernel_size=(1,3), stride=1)        \n",
    "        self.deconv5 = nn.ConvTranspose2d(256, 128, kernel_size=(1,4), stride=1)\n",
    "        self.maxunpool5 = nn.MaxUnpool2d(kernel_size=2, stride=2)        \n",
    "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=(4,4), stride=1)\n",
    "        self.maxunpool4 = nn.MaxUnpool2d(kernel_size=2, stride=2)        \n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, kernel_size=(4,4), stride=1)\n",
    "        self.maxunpool3 = nn.MaxUnpool2d(kernel_size=2, stride=2)        \n",
    "        self.deconv2 = nn.ConvTranspose2d(32, 16, kernel_size=(5,5), stride=1)\n",
    "        self.maxunpool2 = nn.MaxUnpool2d(kernel_size=2, stride=2)        \n",
    "        self.deconv1 = nn.ConvTranspose2d(16, 1, kernel_size=(5,5), stride=1)\n",
    "        self.maxunpool1 = nn.MaxUnpool2d(kernel_size=2, stride=2)       \n",
    "    \n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Encoder\n",
    "        enc = F.relu(self.conv1(x))\n",
    "        enc, mp1 = self.maxpool1(enc)        \n",
    "        enc = F.relu(self.conv2(enc))\n",
    "        enc, mp2 = self.maxpool2(enc)        \n",
    "        enc = F.relu(self.conv3(enc))\n",
    "        enc, mp3 = self.maxpool3(enc)        \n",
    "        enc = F.relu(self.conv4(enc))\n",
    "        enc, mp4 = self.maxpool4(enc)        \n",
    "        enc = F.relu(self.conv5(enc))\n",
    "        enc, mp5 = self.maxpool5(enc)        \n",
    "        enc = F.relu(self.conv6(enc))\n",
    "        \n",
    "        # Reparameterize\n",
    "        mu = self.f11(enc.view(enc.size(0), -1))\n",
    "        logvar = self.f12(enc.view(enc.size(0), -1))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        # Decoder\n",
    "        dec = F.relu(self.f2(z)).view(z.size(0), 512, 2, 3)        \n",
    "        dec = F.relu(self.deconv6(dec))        \n",
    "        dec = self.maxunpool5(dec, mp5)\n",
    "        dec = F.relu(self.deconv5(dec))        \n",
    "        dec = self.maxunpool4(dec, mp4)\n",
    "        dec = F.relu(self.deconv4(dec))        \n",
    "        dec = self.maxunpool3(dec, mp3)\n",
    "        dec = F.relu(self.deconv3(dec))        \n",
    "        dec = self.maxunpool2(dec, mp2)\n",
    "        dec = F.relu(self.deconv2(dec))        \n",
    "        dec = self.maxunpool1(dec, mp1)\n",
    "        \n",
    "        return torch.sigmoid(self.deconv1(dec)), mu, logvar\n",
    "\n",
    "vae = VAE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \n",
    "    generative_loss = F.mse_loss(recon_x.view(-1, im_size), x.view(-1, im_size))\n",
    "\n",
    "    # see Appendix B from:\n",
    "    # Kingma, D. P., &amp; Welling, M. (2014). Auto-Encoding Variational Bayes. Proceedings of the 2nd \n",
    "    # International Conference on Learning Representations (ICLR). Banff, Canada: arXiv: 1312.6114\n",
    "    # v10 [stat. ML].\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return generative_loss + KLD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        vae.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch, data in enumerate(train_loader):\n",
    "            noisy_data, clean_data = func.process_batch(data)\n",
    "            optimizer.zero_grad()\n",
    "            result, mu, logvar = vae(noisy_data)\n",
    "            loss = loss_function(result, clean_data, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if batch % 10 == 0:\n",
    "                print(\"Train Epoch: \", epoch, \"[\", batch * len(data), \"/\", len(train_loader.dataset), \"]\",\n",
    "                      \"\\tLoss: \", loss.item() / len(data))\n",
    "\n",
    "        train_losses.append(train_loss/len(train_loader.dataset))\n",
    "    \n",
    "        vae.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        for val_batch, val_data in enumerate(val_loader):\n",
    "            noisy_val_data, clean_val_data = func.process_batch(data)       \n",
    "            val_result, val_mu, val_logvar = vae(noisy_val_data)\n",
    "            val_loss += loss_function(val_result, clean_val_data, val_mu, val_logvar).item()\n",
    "            \n",
    "        val_losses.append(val_loss/len(val_loader.dataset))\n",
    "\n",
    "        print(\"Train Epoch: \", epoch, \"\\tAverage Training Loss: \", train_loss/len(train_loader.dataset))\n",
    "        print(\"Train Epoch: \", epoch, \"\\tAverage Validation Loss: \", val_loss/len(val_loader.dataset))\n",
    "        \n",
    "        torch.save({\"state_dict\": vae.state_dict(),\n",
    "                    \"optim\": optimizer.state_dict()}, trainedVAE)\n",
    "        np.savez(\"losses.npz\", train_losses = train_losses, val_losses = val_losses)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epochs):\n",
    "    vae.eval()\n",
    "    test_losses = []\n",
    "    results = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        test_loss = 0\n",
    "        \n",
    "        for batch, data in enumerate(test_loader):\n",
    "            noisy_data, clean_data = func.process_batch(data)\n",
    "            result, mu, logvar = vae(noisy_data)\n",
    "            loss = loss_function(result, clean_data, mu, logvar)\n",
    "            test_loss += loss.item()            \n",
    "            results = func.convert_results(result, results)\n",
    "\n",
    "            print(\"Test Epoch: \", epoch, \"[\", batch * len(data), \"/\", len(test_loader.dataset), \"]\",\n",
    "                  \"\\tLoss: \", loss.item() / len(data))\n",
    "\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        print(\"Test Epoch: \", epoch, \"\\tAverage Loss: \", test_loss / len(test_loader.dataset))\n",
    "\n",
    "    return test_losses, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### can be removed\n",
    "model = torch.load(trainedVAE)\n",
    "\n",
    "vae.load_state_dict(model[\"state_dict\"])\n",
    "optimizer.load_state_dict(model[\"optim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  0 [ 0 / 133878 ] \tLoss:  2.9600692869280465e-05\n",
      "Train Epoch:  0 [ 10240 / 133878 ] \tLoss:  3.0485309252981097e-05\n",
      "Train Epoch:  0 [ 20480 / 133878 ] \tLoss:  2.9781769626424648e-05\n",
      "Train Epoch:  0 [ 30720 / 133878 ] \tLoss:  2.9244920369819738e-05\n",
      "Train Epoch:  0 [ 40960 / 133878 ] \tLoss:  2.9793714929837734e-05\n",
      "Train Epoch:  0 [ 51200 / 133878 ] \tLoss:  2.979777673317585e-05\n",
      "Train Epoch:  0 [ 61440 / 133878 ] \tLoss:  2.9352513593039475e-05\n",
      "Train Epoch:  0 [ 71680 / 133878 ] \tLoss:  2.9674676625290886e-05\n",
      "Train Epoch:  0 [ 81920 / 133878 ] \tLoss:  2.9510161766665988e-05\n",
      "Train Epoch:  0 [ 92160 / 133878 ] \tLoss:  2.9752696718787774e-05\n",
      "Train Epoch:  0 [ 102400 / 133878 ] \tLoss:  2.9571787308668718e-05\n",
      "Train Epoch:  0 [ 112640 / 133878 ] \tLoss:  2.916440826083999e-05\n",
      "Train Epoch:  0 [ 122880 / 133878 ] \tLoss:  2.9027867640252225e-05\n",
      "Train Epoch:  0 [ 98540 / 133878 ] \tLoss:  3.854684177835258e-05\n",
      "Train Epoch:  0 \tAverage Training Loss:  2.9613037888298424e-05\n",
      "Train Epoch:  0 \tAverage Validation Loss:  2.8891685561912525e-05\n",
      "Train Epoch:  1 [ 0 / 133878 ] \tLoss:  2.9119724786141887e-05\n",
      "Train Epoch:  1 [ 10240 / 133878 ] \tLoss:  2.8581875085365027e-05\n",
      "Train Epoch:  1 [ 20480 / 133878 ] \tLoss:  2.917444180638995e-05\n",
      "Train Epoch:  1 [ 30720 / 133878 ] \tLoss:  2.8793114324798808e-05\n",
      "Train Epoch:  1 [ 40960 / 133878 ] \tLoss:  2.858491825463716e-05\n",
      "Train Epoch:  1 [ 51200 / 133878 ] \tLoss:  2.918972313636914e-05\n",
      "Train Epoch:  1 [ 61440 / 133878 ] \tLoss:  2.8257039957679808e-05\n",
      "Train Epoch:  1 [ 71680 / 133878 ] \tLoss:  2.8775368264177814e-05\n",
      "Train Epoch:  1 [ 81920 / 133878 ] \tLoss:  2.8226797439856455e-05\n",
      "Train Epoch:  1 [ 92160 / 133878 ] \tLoss:  2.8396663765306585e-05\n",
      "Train Epoch:  1 [ 102400 / 133878 ] \tLoss:  2.909192153310869e-05\n",
      "Train Epoch:  1 [ 112640 / 133878 ] \tLoss:  2.84778270724928e-05\n",
      "Train Epoch:  1 [ 122880 / 133878 ] \tLoss:  2.872763798222877e-05\n",
      "Train Epoch:  1 [ 98540 / 133878 ] \tLoss:  3.8117639681122865e-05\n",
      "Train Epoch:  1 \tAverage Training Loss:  2.883727398182572e-05\n",
      "Train Epoch:  1 \tAverage Validation Loss:  2.8742316328449014e-05\n",
      "Train Epoch:  2 [ 0 / 133878 ] \tLoss:  2.8215363272465765e-05\n",
      "Train Epoch:  2 [ 10240 / 133878 ] \tLoss:  2.8674923669314012e-05\n",
      "Train Epoch:  2 [ 20480 / 133878 ] \tLoss:  2.9207969419076107e-05\n",
      "Train Epoch:  2 [ 30720 / 133878 ] \tLoss:  2.8570639187819324e-05\n",
      "Train Epoch:  2 [ 40960 / 133878 ] \tLoss:  2.8300093617872335e-05\n",
      "Train Epoch:  2 [ 51200 / 133878 ] \tLoss:  2.8181833840790205e-05\n",
      "Train Epoch:  2 [ 61440 / 133878 ] \tLoss:  2.857459185179323e-05\n",
      "Train Epoch:  2 [ 71680 / 133878 ] \tLoss:  2.8274069336475804e-05\n",
      "Train Epoch:  2 [ 81920 / 133878 ] \tLoss:  2.8352269509923644e-05\n",
      "Train Epoch:  2 [ 92160 / 133878 ] \tLoss:  2.8606687919818796e-05\n",
      "Train Epoch:  2 [ 102400 / 133878 ] \tLoss:  2.8232501790625975e-05\n",
      "Train Epoch:  2 [ 112640 / 133878 ] \tLoss:  2.7703810701495968e-05\n",
      "Train Epoch:  2 [ 122880 / 133878 ] \tLoss:  2.7560730814002454e-05\n",
      "Train Epoch:  2 [ 98540 / 133878 ] \tLoss:  3.840626367321115e-05\n",
      "Train Epoch:  2 \tAverage Training Loss:  2.826224479617112e-05\n",
      "Train Epoch:  2 \tAverage Validation Loss:  2.895420932872965e-05\n",
      "Train Epoch:  3 [ 0 / 133878 ] \tLoss:  2.8260747058084235e-05\n",
      "Train Epoch:  3 [ 10240 / 133878 ] \tLoss:  2.752618456725031e-05\n",
      "Train Epoch:  3 [ 20480 / 133878 ] \tLoss:  2.7921918444917537e-05\n",
      "Train Epoch:  3 [ 30720 / 133878 ] \tLoss:  2.8292510251048952e-05\n",
      "Train Epoch:  3 [ 40960 / 133878 ] \tLoss:  2.7826927180285566e-05\n",
      "Train Epoch:  3 [ 51200 / 133878 ] \tLoss:  2.8387459678924643e-05\n",
      "Train Epoch:  3 [ 61440 / 133878 ] \tLoss:  2.7384938221075572e-05\n",
      "Train Epoch:  3 [ 71680 / 133878 ] \tLoss:  2.777812915155664e-05\n",
      "Train Epoch:  3 [ 81920 / 133878 ] \tLoss:  2.7870168196386658e-05\n",
      "Train Epoch:  3 [ 92160 / 133878 ] \tLoss:  2.7272553779766895e-05\n",
      "Train Epoch:  3 [ 102400 / 133878 ] \tLoss:  2.7596383006311953e-05\n",
      "Train Epoch:  3 [ 112640 / 133878 ] \tLoss:  2.7140366000821814e-05\n",
      "Train Epoch:  3 [ 122880 / 133878 ] \tLoss:  2.7582333132158965e-05\n",
      "Train Epoch:  3 [ 98540 / 133878 ] \tLoss:  3.647809912079557e-05\n",
      "Train Epoch:  3 \tAverage Training Loss:  2.782023919130184e-05\n",
      "Train Epoch:  3 \tAverage Validation Loss:  2.7396494018637376e-05\n",
      "Train Epoch:  4 [ 0 / 133878 ] \tLoss:  2.7834861612063833e-05\n",
      "Train Epoch:  4 [ 10240 / 133878 ] \tLoss:  2.722226781770587e-05\n",
      "Train Epoch:  4 [ 20480 / 133878 ] \tLoss:  2.7710966605809517e-05\n",
      "Train Epoch:  4 [ 30720 / 133878 ] \tLoss:  2.730864980549086e-05\n",
      "Train Epoch:  4 [ 40960 / 133878 ] \tLoss:  2.669545756361913e-05\n",
      "Train Epoch:  4 [ 51200 / 133878 ] \tLoss:  2.7517286071088165e-05\n",
      "Train Epoch:  4 [ 61440 / 133878 ] \tLoss:  2.7024261726182885e-05\n",
      "Train Epoch:  4 [ 71680 / 133878 ] \tLoss:  2.7178257369087078e-05\n",
      "Train Epoch:  4 [ 81920 / 133878 ] \tLoss:  2.7303267415845767e-05\n",
      "Train Epoch:  4 [ 92160 / 133878 ] \tLoss:  2.7460333512863144e-05\n",
      "Train Epoch:  4 [ 102400 / 133878 ] \tLoss:  2.7617032174021006e-05\n",
      "Train Epoch:  4 [ 112640 / 133878 ] \tLoss:  2.760075221885927e-05\n",
      "Train Epoch:  4 [ 122880 / 133878 ] \tLoss:  2.7372465410735458e-05\n",
      "Train Epoch:  4 [ 98540 / 133878 ] \tLoss:  3.666747459714205e-05\n",
      "Train Epoch:  4 \tAverage Training Loss:  2.7364956406717363e-05\n",
      "Train Epoch:  4 \tAverage Validation Loss:  2.756550336105698e-05\n",
      "Train Epoch:  5 [ 0 / 133878 ] \tLoss:  2.6504279958317056e-05\n",
      "Train Epoch:  5 [ 10240 / 133878 ] \tLoss:  2.6797559257829562e-05\n",
      "Train Epoch:  5 [ 20480 / 133878 ] \tLoss:  2.729160951275844e-05\n",
      "Train Epoch:  5 [ 30720 / 133878 ] \tLoss:  2.6725912903202698e-05\n",
      "Train Epoch:  5 [ 40960 / 133878 ] \tLoss:  2.7131498427479528e-05\n",
      "Train Epoch:  5 [ 51200 / 133878 ] \tLoss:  2.6942398108076304e-05\n",
      "Train Epoch:  5 [ 61440 / 133878 ] \tLoss:  2.6451842131791636e-05\n",
      "Train Epoch:  5 [ 71680 / 133878 ] \tLoss:  2.6665793484426104e-05\n",
      "Train Epoch:  5 [ 81920 / 133878 ] \tLoss:  2.653127558005508e-05\n",
      "Train Epoch:  5 [ 92160 / 133878 ] \tLoss:  2.6466450435691513e-05\n",
      "Train Epoch:  5 [ 102400 / 133878 ] \tLoss:  2.6652411179384217e-05\n",
      "Train Epoch:  5 [ 112640 / 133878 ] \tLoss:  2.648087865964044e-05\n",
      "Train Epoch:  5 [ 122880 / 133878 ] \tLoss:  2.742943979683332e-05\n",
      "Train Epoch:  5 [ 98540 / 133878 ] \tLoss:  3.560303432724407e-05\n",
      "Train Epoch:  5 \tAverage Training Loss:  2.698260860821175e-05\n",
      "Train Epoch:  5 \tAverage Validation Loss:  2.6766021278829157e-05\n",
      "Train Epoch:  6 [ 0 / 133878 ] \tLoss:  2.6680938390200026e-05\n",
      "Train Epoch:  6 [ 10240 / 133878 ] \tLoss:  2.6712486942415126e-05\n",
      "Train Epoch:  6 [ 20480 / 133878 ] \tLoss:  2.693945680221077e-05\n",
      "Train Epoch:  6 [ 30720 / 133878 ] \tLoss:  2.6597064788802527e-05\n",
      "Train Epoch:  6 [ 40960 / 133878 ] \tLoss:  2.6573312425171025e-05\n",
      "Train Epoch:  6 [ 51200 / 133878 ] \tLoss:  2.726400998653844e-05\n",
      "Train Epoch:  6 [ 61440 / 133878 ] \tLoss:  2.6897305360762402e-05\n",
      "Train Epoch:  6 [ 71680 / 133878 ] \tLoss:  2.6859483114094473e-05\n",
      "Train Epoch:  6 [ 81920 / 133878 ] \tLoss:  2.6788891773321666e-05\n",
      "Train Epoch:  6 [ 92160 / 133878 ] \tLoss:  2.6966725272359326e-05\n",
      "Train Epoch:  6 [ 102400 / 133878 ] \tLoss:  2.662841507117264e-05\n",
      "Train Epoch:  6 [ 112640 / 133878 ] \tLoss:  2.6271274691680446e-05\n",
      "Train Epoch:  6 [ 122880 / 133878 ] \tLoss:  2.6844187232200056e-05\n",
      "Train Epoch:  6 [ 98540 / 133878 ] \tLoss:  3.5986407490393103e-05\n",
      "Train Epoch:  6 \tAverage Training Loss:  2.663908522823133e-05\n",
      "Train Epoch:  6 \tAverage Validation Loss:  2.7126087211743812e-05\n",
      "Train Epoch:  7 [ 0 / 133878 ] \tLoss:  2.583235254860483e-05\n",
      "Train Epoch:  7 [ 10240 / 133878 ] \tLoss:  2.617400787130464e-05\n",
      "Train Epoch:  7 [ 20480 / 133878 ] \tLoss:  2.6020861696451902e-05\n",
      "Train Epoch:  7 [ 30720 / 133878 ] \tLoss:  2.639059857756365e-05\n",
      "Train Epoch:  7 [ 40960 / 133878 ] \tLoss:  2.6260810045641847e-05\n",
      "Train Epoch:  7 [ 51200 / 133878 ] \tLoss:  2.5645138521213084e-05\n",
      "Train Epoch:  7 [ 61440 / 133878 ] \tLoss:  2.6055105990963057e-05\n",
      "Train Epoch:  7 [ 71680 / 133878 ] \tLoss:  2.5810475563048385e-05\n",
      "Train Epoch:  7 [ 81920 / 133878 ] \tLoss:  2.595767546154093e-05\n",
      "Train Epoch:  7 [ 92160 / 133878 ] \tLoss:  2.5933484721463174e-05\n",
      "Train Epoch:  7 [ 102400 / 133878 ] \tLoss:  2.5636560167185962e-05\n",
      "Train Epoch:  7 [ 112640 / 133878 ] \tLoss:  2.57412302744342e-05\n",
      "Train Epoch:  7 [ 122880 / 133878 ] \tLoss:  2.5923050998244435e-05\n",
      "Train Epoch:  7 [ 98540 / 133878 ] \tLoss:  3.432830191146101e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  7 \tAverage Training Loss:  2.615375628195109e-05\n",
      "Train Epoch:  7 \tAverage Validation Loss:  2.5815129168019728e-05\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1 = plt.figure()\n",
    "ax = f1.add_subplot(111)\n",
    "ax.plot(train_losses[1:], label=\"Training Loss\")\n",
    "ax.plot(val_losses[1:], label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Training Loss\")\n",
    "ax.set_xlabel(\"epochs\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "f1.savefig(\"training_losses.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch:  0 [ 0 / 8689 ] \tLoss:  2.2545220417669043e-05\n",
      "Test Epoch:  0 [ 1024 / 8689 ] \tLoss:  2.2980293579166755e-05\n",
      "Test Epoch:  0 [ 2048 / 8689 ] \tLoss:  2.357387165830005e-05\n",
      "Test Epoch:  0 [ 3072 / 8689 ] \tLoss:  2.409341323073022e-05\n",
      "Test Epoch:  0 [ 4096 / 8689 ] \tLoss:  2.314772063982673e-05\n",
      "Test Epoch:  0 [ 5120 / 8689 ] \tLoss:  2.2332562366500497e-05\n",
      "Test Epoch:  0 [ 6144 / 8689 ] \tLoss:  2.212718754890375e-05\n",
      "Test Epoch:  0 [ 7168 / 8689 ] \tLoss:  2.107146974594798e-05\n",
      "Test Epoch:  0 [ 3976 / 8689 ] \tLoss:  4.285695387324097e-05\n",
      "Test Epoch:  0 \tAverage Loss:  2.3884977212859345e-05\n"
     ]
    }
   ],
   "source": [
    "test_losses, testing_results = test(1)\n",
    "\n",
    "### can be removed\n",
    "with open('test_results.npz', 'wb') as f:\n",
    "    np.savez(f, results = testing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8689, 112, 256)\n"
     ]
    }
   ],
   "source": [
    "### can be removed\n",
    "testing_results = np.load('test_results.npz')['results']\n",
    "print(testing_results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Testing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Split Indices\n",
    "Finds indices on which to split the testing results data, in order to make sure that all the sound chunks belonging to a speech sample are in the same array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_indices = func.create_split_indices(testing_noisy_dir_chunks)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Spectrograms Back To Sound\n",
    "Convert all the spectrograms that are created by the network back to sound fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = func.spec_to_sound(testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data\n",
    "Splits the data on the indices previously computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_chunks = np.split(audio, split_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Sound Fragmets\n",
    "Appends all sound chunks belonging to a speech sample and saves them in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.save_sound_to_dir(sound_chunks, new_rate, testing_noisy_dir, testing_results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CI simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Frequency Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_channels = 22\n",
    "freq_ranges = freqs.compute_frequency_ranges(nr_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Simulated Data\n",
    "Creates simulated data for both the original noisy data, as well as the data generated by the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 15\n",
    "func.convert_to_sim_data(testing_noisy_dir, testing_noisy_dir_simulated, freq_ranges, samples)\n",
    "func.convert_to_sim_data(testing_results_dir, testing_results_dir_simulated, freq_ranges, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
